<!DOCTYPE html>
<html lang="en" >
<head>
  <meta charset="UTF-8">
  <title>CodePen - EncoreLearningTesting</title>
  

</head>
<body>
<!-- partial:index.partial.html -->
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Speech to Text</title>
    <style>
      body {
        font-family: Arial, sans-serif;
        background-color: #f4f4f9;
        color: #333;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        height: 100vh;
        margin: 0;
      }

      h1 {
        color: #4a90e2;
        margin-bottom: 20px;
      }

      button {
        background-color: #4a90e2;
        color: white;
        border: none;
        padding: 10px 20px;
        margin: 5px;
        border-radius: 5px;
        cursor: pointer;
        font-size: 16px;
      }

      button:hover {
        background-color: #357abd;
      }

      #output {
        margin-top: 20px;
        padding: 10px;
        width: 80%;
        background-color: #fff;
        border: 1px solid #ccc;
        border-radius: 5px;
        min-height: 100px;
        white-space: pre-wrap;
        word-wrap: break-word;
        text-align: left;
        font-size: 16px;
        color: #555;
      }
    </style>
  </head>
  <body>
    <h1>Speech to Text</h1>
    <button id="start-btn">Start</button>
    <button id="stop-btn">Stop</button>
    <div id="output">The transcript will appear here...</div>

    <script>
      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;
      const recognition = new SpeechRecognition();

      const output = document.querySelector("#output");
      const startBtn = document.querySelector("#start-btn");
      const stopBtn = document.querySelector("#stop-btn");

      recognition.continuous = true;

      startBtn.addEventListener("click", () => {
        recognition.start();
      });

      stopBtn.addEventListener("click", () => {
        recognition.stop();
      });

      recognition.addEventListener("result", (event) => {
        const transcript = Array.from(event.results)
          .map((result) => result[0].transcript)
          .join("");
        
        output.textContent = transcript;

        // API call function to send transcript
        const sendTranscript = async (transcript) => {
          const data = {
            timestamp: new Date().toISOString(),
            roomName: "encorelearningtesting",
            description: "Description2",
            transcript: transcript,
            isActivelyStreaming: true,
            translation: "Translation2",
            inputLanguage: "en",
            outputLanguage: "de",
            isPremiumCustomer: true,
          };

          try {
            const response = await fetch("https://api.deafassistant.com/stream/LiteSmartAdd", {
              method: "POST",
              headers: {
                "Content-Type": "application/json",
              },
              body: JSON.stringify(data),
            });

            if (!response.ok) {
              throw new Error("Failed to send transcript");
            }

            console.log("Transcript sent successfully");
          } catch (error) {
            console.error(error.message);
          }
        };

        // Send the transcript to the API
        sendTranscript(transcript);
      });
    </script>
  </body>
<!-- partial -->
  
</body>
</html>
